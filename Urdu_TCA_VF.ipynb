{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ee6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:374: SyntaxWarning: invalid escape sequence '\\I'\n",
      "<>:374: SyntaxWarning: invalid escape sequence '\\I'\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10900\\4176248697.py:374: SyntaxWarning: invalid escape sequence '\\I'\n",
      "  process_docx_file(\"D:\\IPS assignments\\Assignment 5\\Ù‚Ø±Ø¢Ù† Ø­Ú©ÛŒÙ… Ø§Ø±ØªÙ‚Ø§ÛŒ Ø¹Ù„ÛŒ Ø¨Ù†Ø¯Ú¯ÛŒ.docx\", \"cleanedf.docx\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 0 repetitive headers to remove.\n",
      "âœ… Urdu document cleaned: cleanedf.docx\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "URDU-ONLY OCR CLEANER & DOCX REBUILDER\n",
    "------------------------------------\n",
    "â€¢ Paragraph-level Urdu processing\n",
    "â€¢ Nastaliq-safe layout\n",
    "â€¢ Header detection & removal\n",
    "â€¢ Urdu spell highlighting\n",
    "â€¢ OCR normalization\n",
    "â€¢ Soft-split paragraph merging\n",
    "â€¢ NO English logic\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import docx\n",
    "from collections import Counter\n",
    "from docx.shared import Pt, Inches\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH, WD_COLOR_INDEX\n",
    "from docx.oxml import OxmlElement\n",
    "from docx.oxml.ns import qn\n",
    "from wordfreq import zipf_frequency\n",
    "from docx.shared import Pt\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONSTANTS (HARD-LOCKED AS REQUESTED)\n",
    "# ============================================================\n",
    "\n",
    "URDU_FONT = \"Jameel Noori Nastaleeq\"\n",
    "URDU_FONT_SIZE = Pt(14)\n",
    "URDU_LANG = \"ur-PK\"\n",
    "SPELL_THRESHOLD = 1.6   # aggressive (as requested)\n",
    "\n",
    "URDU_CHAR_RE = re.compile(r'[\\u0600-\\u06FF\\u0750-\\u077F]')\n",
    "URDU_WORD_RE = re.compile(r'[\\u0600-\\u06FF\\u0750-\\u077F]+')\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BASIC UTILITIES\n",
    "# ============================================================\n",
    "\n",
    "def is_urdu_text(text: str) -> bool:\n",
    "    return bool(URDU_CHAR_RE.search(text))\n",
    "\n",
    "\n",
    "def normalize_urdu_text(text: str) -> str:\n",
    "    \"\"\"Unicode- and OCR-safe normalization for Urdu.\"\"\"\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    # Normalize spaces\n",
    "    text = text.replace(\"\\u00A0\", \" \")\n",
    "    text = re.sub(r\"[ \\t\\f\\v]+\", \" \", text)\n",
    "\n",
    "    # Remove zero-width junk\n",
    "    text = re.sub(r\"[\\u200B\\u200C\\u200D\\uFEFF]\", \"\", text)\n",
    "\n",
    "    # Normalize line breaks\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    # Urdu punctuation normalization\n",
    "    text = text.replace(\"Ù¬\", \"ØŒ\")\n",
    "    text = text.replace(\"Ù«\", \"Û”\")\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def is_valid_urdu_word(word: str) -> bool:\n",
    "    \"\"\"Frequency-based Urdu word validation.\"\"\"\n",
    "    word = re.sub(r\"[\\u200B\\u200C\\u200D\\uFEFF]\", \"\", word)\n",
    "    return zipf_frequency(word, \"ur\") >= SPELL_THRESHOLD\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# HEADER DETECTION & REMOVAL (URDU-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "AUDIT_HEADER = [\"file\", \"para_index\", \"action\", \"pattern\", \"before_preview\", \"after_preview\"]\n",
    "\n",
    "\n",
    "def detect_repetitive_headers(paragraphs, min_repeats=3):\n",
    "    normalized = []\n",
    "\n",
    "    for p in paragraphs:\n",
    "        line = p.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "\n",
    "        # Skip numeric-only or decorative lines\n",
    "        if re.match(r'^[-â€“â€”]*\\s*\\(?\\d{1,3}\\)?\\s*[-â€“â€”]*$', line):\n",
    "            continue\n",
    "\n",
    "        # Require some Urdu content\n",
    "        if not is_urdu_text(line):\n",
    "            continue\n",
    "\n",
    "        normalized.append(line)\n",
    "\n",
    "    counts = Counter(normalized)\n",
    "\n",
    "    return {\n",
    "        line for line, freq in counts.items()\n",
    "        if freq >= min_repeats\n",
    "    }\n",
    "\n",
    "\n",
    "def remove_known_headers(paragraphs, detected_headers, audit_writer=None, filename=None):\n",
    "    filtered = []\n",
    "    seen = set()\n",
    "\n",
    "    for i, para in enumerate(paragraphs):\n",
    "        stripped = para.strip()\n",
    "\n",
    "        if stripped in detected_headers:\n",
    "            if stripped not in seen:\n",
    "                seen.add(stripped)\n",
    "                filtered.append(para)\n",
    "            else:\n",
    "                if audit_writer:\n",
    "                    audit_writer.writerow([\n",
    "                        filename or \"\",\n",
    "                        i,\n",
    "                        \"remove_header\",\n",
    "                        \"repetitive_header\",\n",
    "                        stripped[:80],\n",
    "                        \"\"\n",
    "                    ])\n",
    "            continue\n",
    "\n",
    "        filtered.append(para)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "def clean_urdu_numeric_artifacts(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Urdu-safe numeric & artifact cleaner.\n",
    "    Designed specifically for religious / academic Urdu OCR text.\n",
    "    \"\"\"\n",
    "\n",
    "    if not text:\n",
    "        return text\n",
    "\n",
    "    # Normalize line endings\n",
    "    text = text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "    # Split into paragraphs\n",
    "    paras = text.split('\\n\\n')\n",
    "    cleaned = []\n",
    "\n",
    "    for para in paras:\n",
    "        p = para.strip()\n",
    "\n",
    "        if not p:\n",
    "            continue\n",
    "\n",
    "        # 1. Remove standalone numeric lines (Urdu or Latin digits)\n",
    "        if re.fullmatch(r'[Û°-Û¹0-9]{1,3}', p):\n",
    "            continue\n",
    "\n",
    "        # 2. Remove decorative page numbers: - 13 -, (14), â€” 15 â€”\n",
    "        if re.fullmatch(r'[-â€“â€”]?\\s*\\(?[Û°-Û¹0-9]{1,3}\\)?\\s*[-â€“â€”]?', p):\n",
    "            continue\n",
    "\n",
    "        # 3. Remove pure numeric footnotes like [12] or (12)\n",
    "        if re.fullmatch(r'[\\[\\(]\\s*[Û°-Û¹0-9]{1,3}\\s*[\\]\\)]', p):\n",
    "            continue\n",
    "\n",
    "        cleaned.append(p)\n",
    "\n",
    "    text = '\\n\\n'.join(cleaned)\n",
    "\n",
    "    # 4. Protect time formats: 11.40 A.M â†’ 11:40 A.M\n",
    "    text = re.sub(\n",
    "        r'\\b(\\d{1,2})\\.(\\d{2})\\s*(A\\.M|P\\.M)\\b',\n",
    "        r'\\1:\\2 \\3',\n",
    "        text,\n",
    "        flags=re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    # 5. Collapse excessive newlines\n",
    "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "# ============================================================\n",
    "# URDU SPELL HIGHLIGHTING (SAFE)\n",
    "# ============================================================\n",
    "\n",
    "def highlight_urdu_misspellings(paragraph):\n",
    "    \"\"\"\n",
    "    Highlight misspelled Urdu words.\n",
    "\n",
    "    \"\"\"\n",
    "    text = paragraph.text\n",
    "    if not text.strip():\n",
    "        return\n",
    "\n",
    "    misspelled = {\n",
    "        w for w in URDU_WORD_RE.findall(text)\n",
    "        if len(w) >= 3 and not is_valid_urdu_word(w)\n",
    "    }\n",
    "\n",
    "    if not misspelled:\n",
    "        return\n",
    "\n",
    "    # Clear paragraph text only (no formatting logic)\n",
    "    paragraph._p.clear_content()\n",
    "\n",
    "    parts = re.split(r'([\\u0600-\\u06FF\\u0750-\\u077F]+)', text)\n",
    "\n",
    "    for part in parts:\n",
    "        run = paragraph.add_run(part)\n",
    "\n",
    "        # ONLY highlight â€” nothing else\n",
    "        if part in misspelled:\n",
    "            run.font.highlight_color = WD_COLOR_INDEX.YELLOW\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PARAGRAPH FORMATTING (FINAL PASS)\n",
    "# ============================================================\n",
    "\n",
    "def set_run_urdu_properties(run, urdu_font_name = URDU_FONT, lang_code=\"ur-PK\"):\n",
    "    # 1) set font metadata (ASCII/complex script)\n",
    "    try:\n",
    "        run.font.name = urdu_font_name\n",
    "        r = run._element\n",
    "        # set complex script font (for Urdu)\n",
    "        r.rPr.rFonts.set(qn('w:cs'), urdu_font_name)\n",
    "        # also set ascii/hAnsi to the same font to help some viewers\n",
    "        try:\n",
    "            r.rPr.rFonts.set(qn('w:ascii'), urdu_font_name)\n",
    "            r.rPr.rFonts.set(qn('w:hAnsi'), urdu_font_name)\n",
    "        except Exception:\n",
    "            pass\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) language tag\n",
    "    try:\n",
    "        rPr = run._element.rPr\n",
    "        if rPr is None:\n",
    "            rPr = OxmlElement('w:rPr')\n",
    "            run._element.insert(0, rPr)\n",
    "        # remove existing w:lang if present\n",
    "        for child in list(rPr):\n",
    "            if child.tag == qn('w:lang'):\n",
    "                rPr.remove(child)\n",
    "        lang = OxmlElement('w:lang')\n",
    "        lang.set(qn('w:val'), lang_code)\n",
    "        rPr.append(lang)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) mark run as RTL at run-level (helps Word render & proofing)\n",
    "    try:\n",
    "        rtl_run = OxmlElement('w:rtl')\n",
    "        rtl_run.set(qn('w:val'), \"1\")\n",
    "        # remove existing run-level rtl if present\n",
    "        for child in list(rPr):\n",
    "            if child.tag == qn('w:rtl'):\n",
    "                rPr.remove(child)\n",
    "        rPr.append(rtl_run)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def set_paragraph_rtl(paragraph):\n",
    "    # 1) set paragraph alignment to justify (visual)\n",
    "    try:\n",
    "        paragraph.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) set paragraph-level RTL / bidi flags in XML\n",
    "    p = paragraph._p\n",
    "    pPr = p.get_or_add_pPr()\n",
    "    # remove existing flags if present, then add both to be safe\n",
    "    try:\n",
    "        # Remove any existing w:rtl or w:bidi children\n",
    "        for child in list(pPr):\n",
    "            if child.tag in (qn('w:rtl'), qn('w:bidi')):\n",
    "                pPr.remove(child)\n",
    "        # Add w:rtl w:val=\"1\"\n",
    "        rtl = OxmlElement('w:rtl')\n",
    "        rtl.set(qn('w:val'), \"1\")\n",
    "        pPr.append(rtl)\n",
    "        # Also add w:bidi w:val=\"1\" (some Word versions check this)\n",
    "        bidi = OxmlElement('w:bidi')\n",
    "        bidi.set(qn('w:val'), \"1\")\n",
    "        pPr.append(bidi)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "def apply_urdu_font_size(run, size_pt):\n",
    "    \"\"\"\n",
    "    Apply font size for complex scripts (Urdu).\n",
    "    DOES NOT touch font name or other properties.\n",
    "    \"\"\"\n",
    "    rPr = run._element.get_or_add_rPr()\n",
    "\n",
    "    size_val = str(int(size_pt.pt * 2))  # Word uses half-points\n",
    "\n",
    "    # Remove existing size nodes to avoid conflicts\n",
    "    for child in list(rPr):\n",
    "        if child.tag in (qn('w:sz'), qn('w:szCs')):\n",
    "            rPr.remove(child)\n",
    "\n",
    "    sz = OxmlElement('w:sz')\n",
    "    sz.set(qn('w:val'), size_val)\n",
    "\n",
    "    szCs = OxmlElement('w:szCs')\n",
    "    szCs.set(qn('w:val'), size_val)\n",
    "\n",
    "    rPr.append(sz)\n",
    "    rPr.append(szCs)\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FINAL DOCX PROCESSOR (URDU-ONLY)\n",
    "# ============================================================\n",
    "\n",
    "def process_docx_file(input_path, output_docx, audit_csv_path=None, audit=False):\n",
    "    input_path = Path(input_path)\n",
    "    if not input_path.exists():\n",
    "        raise FileNotFoundError(input_path)\n",
    "\n",
    "    doc = docx.Document(str(input_path))\n",
    "    raw_paras = [\n",
    "        \"\".join(r.text for r in p.runs).strip()\n",
    "        for p in doc.paragraphs\n",
    "        if p.text.strip()\n",
    "    ]\n",
    "\n",
    "    if audit:\n",
    "        audit_file = open(audit_csv_path, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "        audit_writer = csv.writer(audit_file)\n",
    "        audit_writer.writerow(AUDIT_HEADER)\n",
    "    else:\n",
    "        audit_writer = None\n",
    "        audit_file = None\n",
    "\n",
    "    # Normalize OCR text (Urdu only)\n",
    "    cleaned = [\n",
    "        clean_urdu_numeric_artifacts(\n",
    "            normalize_urdu_text(p)\n",
    "        )\n",
    "        for p in raw_paras\n",
    "        if is_urdu_text(p)\n",
    "    ]\n",
    "\n",
    "    # Header detection & removal\n",
    "    headers = detect_repetitive_headers(cleaned)\n",
    "    print(f\"Detected {len(headers)} repetitive headers to remove.\")\n",
    "    cleaned = remove_known_headers(\n",
    "        cleaned,\n",
    "        headers,\n",
    "        audit_writer=audit_writer,\n",
    "        filename=input_path.name\n",
    "    )\n",
    "\n",
    "    # Build new document\n",
    "    new = docx.Document()\n",
    "\n",
    "    for para_text in cleaned:\n",
    "        p = new.add_paragraph()\n",
    "        p.add_run(para_text)\n",
    "\n",
    "        # Highlight misspellings FIRST\n",
    "        highlight_urdu_misspellings(p)\n",
    "\n",
    "        # Final paragraph formatting\n",
    "        for run in p.runs:\n",
    "            set_run_urdu_properties(run)\n",
    "        set_paragraph_rtl(p)\n",
    "        for run in p.runs:\n",
    "            apply_urdu_font_size(run, URDU_FONT_SIZE)\n",
    "    # Margins\n",
    "    for sec in new.sections:\n",
    "        sec.top_margin = Inches(1)\n",
    "        sec.bottom_margin = Inches(1)\n",
    "        sec.left_margin = Inches(1)\n",
    "        sec.right_margin = Inches(1)\n",
    "\n",
    "    new.save(output_docx)\n",
    "\n",
    "    if audit_file:\n",
    "        audit_file.close()\n",
    "\n",
    "    print(\"âœ… Urdu document cleaned:\", output_docx)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FOLDER PROCESSOR\n",
    "# ============================================================\n",
    "\n",
    "def process_folder(root_dir, overwrite=False, audit=False):\n",
    "    root = Path(root_dir)\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(root)\n",
    "\n",
    "    for subdir in root.iterdir():\n",
    "        if not subdir.is_dir():\n",
    "            continue\n",
    "\n",
    "        for docx_file in subdir.glob(\"*.docx\"):\n",
    "            if docx_file.name.startswith(\"~$\"):\n",
    "                continue\n",
    "\n",
    "            output_docx = subdir / f\"{docx_file.stem}.cleaned.docx\"\n",
    "            audit_csv = subdir / f\"{docx_file.stem}.audit.csv\" if audit else None\n",
    "\n",
    "            if output_docx.exists() and not overwrite:\n",
    "                print(\"Skipping:\", output_docx)\n",
    "                continue\n",
    "\n",
    "            print(\"ðŸ“˜ Processing:\", docx_file.name)\n",
    "\n",
    "            process_docx_file(\n",
    "                input_path=str(docx_file),\n",
    "                output_docx=str(output_docx),\n",
    "                audit_csv_path=str(audit_csv) if audit else None,\n",
    "                audit=audit\n",
    "            )\n",
    "\n",
    "process_docx_file(\"D:\\IPS assignments\\Assignment 5\\Ù‚Ø±Ø¢Ù† Ø­Ú©ÛŒÙ… Ø§Ø±ØªÙ‚Ø§ÛŒ Ø¹Ù„ÛŒ Ø¨Ù†Ø¯Ú¯ÛŒ.docx\", \"cleanedf.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
